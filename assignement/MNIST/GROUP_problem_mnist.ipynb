{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_28x28_train = np.load(\"mnist_28x28_train.npy\")\n",
    "mnist_8x8_train = np.load(\"mnist_8x8_train.npy\")\n",
    "train_labels = np.load(\"train_labels.npy\")\n",
    "\n",
    "mnist_28x28_test = np.load(\"mnist_28x28_test.npy\")\n",
    "mnist_8x8_test = np.load(\"mnist_8x8_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def k_fold_fit_and_evaluate(X, y, model, scoring_method, n_splits=5):\n",
    "    # define evaluation procedure\n",
    "    cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    # evaluate model\n",
    "    scores = cross_validate(model, X, y, scoring=scoring_method, cv=cv, n_jobs=-1)\n",
    "    \n",
    "       \n",
    "    return scores[\"test_score\"]\n",
    "\n",
    "scoring_method = make_scorer(lambda prediction, true_target: f1_score(prediction, true_target, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=None, min_samples_leaf=2, random_state=42),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(n_neighbors=3, weights=\"distance\"),\n",
    "    \"SVM\": SVC(C=10, kernel=\"poly\", random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(C=10, random_state=42, max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Hint: `plt.imshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(train_labels))\n",
    "print(\"Train 8 shape: \", mnist_8x8_train.shape)\n",
    "print(\"Train 28 shape: \", mnist_28x28_train.shape)\n",
    "print(\"Test 8 shape: \", mnist_8x8_test.shape)\n",
    "print(\"Test 28 shape: \", mnist_28x28_test.shape)\n",
    "print(\"Labels size: \", len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "i = 0\n",
    "for m in mnist_8x8_test:\n",
    "    if i < 10:\n",
    "        plt.imshow(m)\n",
    "        plt.show()\n",
    "        i += 1\n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "i = 0\n",
    "for m in mnist_28x28_train:\n",
    "    if i < 10:\n",
    "        plt.imshow(m)\n",
    "        plt.show()\n",
    "        i += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all values to between 0 and 1\n",
    "# Didn't make any difference\n",
    "scale_train_8 = mnist_8x8_train / 255.0\n",
    "scale_test_8 = mnist_8x8_test / 255.0\n",
    "scale_train_28 = mnist_28x28_train / 255.0\n",
    "scale_test_28 = mnist_28x28_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "nsam_train, nxx, nyy = scale_train_8.shape\n",
    "tmp_train_8 = scale_train_8.reshape(nsam_train, nxx * nyy)\n",
    "X_fit_trans_8_train = Normalizer().fit_transform(tmp_train_8)\n",
    "X_reshape_8_train = X_fit_trans_8_train.reshape(nsam_train, nxx, nyy)\n",
    "\n",
    "nsam_train, nxx, nyy = scale_test_8.shape\n",
    "tmp_test_8 = scale_test_8.reshape(nsam_train, nxx * nyy)\n",
    "X_fit_trans_8_test = Normalizer().fit_transform(tmp_test_8)\n",
    "X_reshape_8_test = X_fit_trans_8_test.reshape(nsam_train, nxx, nyy)\n",
    "\n",
    "nsam_train, nxx, nyy = scale_train_28.shape\n",
    "tmp_train_28 = scale_train_28.reshape(nsam_train, nxx * nyy)\n",
    "X_fit_trans_28_train = Normalizer().fit_transform(tmp_train_28)\n",
    "X_reshape_28_train = X_fit_trans_28_train.reshape(nsam_train, nxx, nyy)\n",
    "\n",
    "nsam_train, nxx, nyy = scale_test_28.shape\n",
    "tmp_test_28 = scale_test_28.reshape(nsam_train, nxx * nyy)\n",
    "X_fit_trans_28_test = Normalizer().fit_transform(tmp_test_28)\n",
    "X_reshape_28_test = X_fit_trans_28_test.reshape(nsam_train, nxx, nyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X8_train, X8_test, y8_train, y8_test = train_test_split(X_reshape_8_train, \n",
    "                                train_labels, test_size=0.1, random_state=42, shuffle=True, stratify=train_labels)\n",
    "\n",
    "X28_train, X28_test, y28_train, y28_test = train_test_split(X_reshape_28_train, \n",
    "                                train_labels, test_size=0.1, random_state=42, shuffle=True, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "# TODO\n",
    "def fit_predict(X_train, X_test, y_train, y_test):\n",
    "    table = []\n",
    "    for name, model in models.items():\n",
    "        nsamples_train, nx, ny = X_train.shape\n",
    "        X_flat_train = X_train.reshape((nsamples_train,nx*ny))\n",
    "\n",
    "        nsamples_test, nx, ny = X_test.shape\n",
    "        X_flat_test = X_test.reshape((nsamples_test,nx*ny))\n",
    "\n",
    "        model.fit(X_flat_train, y_train)\n",
    "        pred = model.predict(X_flat_test)\n",
    "        f = f1_score(pred, y_test, average='weighted')\n",
    "        acc = accuracy_score(pred, y_test)\n",
    "        \n",
    "        table.append([name, f, acc])\n",
    "    return X_flat_train, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold\n",
    "def kfold_fit_eval(X_kfold_train, y_train):\n",
    "    table2 = []\n",
    "    for name, model in models.items():\n",
    "        tmp_acc = k_fold_fit_and_evaluate(X_kfold_train, y_train, model, scoring_method)\n",
    "        m_acc = np.mean(tmp_acc)\n",
    "        std_acc = np.std(tmp_acc)\n",
    "        table2.append([name, m_acc, std_acc])\n",
    "    return table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                          F1    Accuracy\n",
      "----------------------  --------  ----------\n",
      "GaussianNB              0.663124    0.626667\n",
      "DecisionTreeClassifier  0.762462    0.762667\n",
      "KNeighborsClassifier    0.930339    0.930667\n",
      "SVM                     0.95991     0.96\n",
      "LogisticRegression      0.898203    0.898667\n",
      "Name                        Mean    Std_Acc\n",
      "----------------------  --------  ---------\n",
      "GaussianNB              0.663124   0.626667\n",
      "DecisionTreeClassifier  0.762462   0.762667\n",
      "KNeighborsClassifier    0.930339   0.930667\n",
      "SVM                     0.95991    0.96\n",
      "LogisticRegression      0.898203   0.898667\n"
     ]
    }
   ],
   "source": [
    "X_kfold_train, table = fit_predict(X8_train, X8_test, y8_train, y8_test)\n",
    "table2 = kfold_fit_eval(X_kfold_train, y8_train)\n",
    "print(tabulate(table, headers=['Name', 'F1', 'Accuracy']))\n",
    "print(tabulate(table, headers=['Name', 'Mean', 'Std_Acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                          F1    Accuracy\n",
      "----------------------  --------  ----------\n",
      "GaussianNB              0.623049    0.581333\n",
      "DecisionTreeClassifier  0.723819    0.72\n",
      "KNeighborsClassifier    0.936158    0.936\n",
      "SVM                     0.949388    0.949333\n",
      "LogisticRegression      0.89589     0.896\n",
      "Name                        Mean    Std_Acc\n",
      "----------------------  --------  ---------\n",
      "GaussianNB              0.623049   0.581333\n",
      "DecisionTreeClassifier  0.723819   0.72\n",
      "KNeighborsClassifier    0.936158   0.936\n",
      "SVM                     0.949388   0.949333\n",
      "LogisticRegression      0.89589    0.896\n"
     ]
    }
   ],
   "source": [
    "X_kfold_train_28, table = fit_predict(X28_train, X28_test, y28_train, y28_test)\n",
    "table2 = kfold_fit_eval(X_kfold_train_28, y28_train)\n",
    "print(tabulate(table, headers=['Name', 'F1', 'Accuracy']))\n",
    "print(tabulate(table, headers=['Name', 'Mean', 'Std_Acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "prediction = np.array([-1] * len(mnist_8x8_test)) #TODO replace this with you own prediction\n",
    "pd.DataFrame(prediction).to_csv(\"GROUP_classes_problem_mnist.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data - the pixels are already well seperated, quality improves by a lot in 28x28 compared to 8x8. \n",
    "# A simple normaliztion should be sufficient.\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# sc = NDNormalizer()\n",
    "# x8_train = sc.transform(sc.fit(mnist_8x8_train))\n",
    "# x28_train = sc.transform(sc.fit(mnist_28x28_train))\n",
    "\n",
    "sc = Normalizer()\n",
    "X8_transform_train = np.full_like(mnist_8x8_train, fill_value=0)\n",
    "X8_transform_test = np.full_like(mnist_8x8_test, fill_value=0)\n",
    "# x8_test = np.full_like(mnist_8x8_test, fill_value=0)\n",
    "# x28_test = np.full_like(mnist_28x28_test, fill_value=0)\n",
    "\n",
    "for i in range(mnist_8x8_train.shape[1]):\n",
    "    X8_transform_train[:, i, :] = sc.fit_transform(mnist_8x8_train[:, i, :]) \n",
    "\n",
    "for i in range(mnist_8x8_test.shape[1]):\n",
    "    X8_transform_test[:, i, :] = sc.transform(mnist_8x8_test[:, i, :])\n",
    "        \n",
    "# for i in range(mnist_28x28_train.shape[1]):\n",
    "#     x28_train[:, i, :] = sc.fit_transform(mnist_28x28_train[:, i, :]) \n",
    "\n",
    "# for i in range(mnist_28x28_test.shape[1]):\n",
    "#     x28_test[:, i, :] = sc.transform(mnist_28x28_test[:, i, :])\n",
    "\n",
    "i = 0\n",
    "for m in X8_transform_train:\n",
    "    if i < 10:\n",
    "        plt.imshow(m)\n",
    "        plt.show()\n",
    "        i += 1\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "class NDNormalizer(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._scaler = Normalizer(copy=True, **kwargs)\n",
    "        self._orig_shape = None\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        # Save the original shape to reshape the flattened X later\n",
    "        # back to its original shape\n",
    "        if len(X.shape) > 1:\n",
    "            self._orig_shape = X.shape[1:]\n",
    "        X = self._flatten(X)\n",
    "        self._scaler.fit(X, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "\n",
    "    def _flatten(self, X):\n",
    "        # Reshape X to <= 2 dimensions\n",
    "        if len(X.shape) > 2:\n",
    "            n_dims = np.prod(self._orig_shape)\n",
    "            X = X.reshape(-1, n_dims)\n",
    "        return X\n",
    "\n",
    "    def _reshape(self, X):\n",
    "        # Reshape X back to it's original shape\n",
    "        if len(X.shape) >= 2:\n",
    "            X = X.reshape(-1, *self._orig_shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_pixels(pixels_df):\n",
    "    \"\"\"Removes from the images the pixels that have a constant intensity value,\n",
    "    either always black (0) or white (255)\n",
    "    Returns the cleared dataset & the list of the removed pixels (columns)\"\"\"\n",
    "\n",
    "    #Remove the pixels that are always black to compute faster\n",
    "    changing_pixels_df = pixels_df.loc[:]\n",
    "    dropped_pixels_b = []\n",
    "\n",
    "    #Pixels with max value =0 are pixels that never change\n",
    "    for col in pixels_df:\n",
    "        if changing_pixels_df[col].max() == 0:\n",
    "            changing_pixels_df.drop(columns=[col], inplace=True)\n",
    "            dropped_pixels_b.append(col)\n",
    "    print(\"Constantly black pixels that have been dropped: {}\".format(dropped_pixels_b))\n",
    "\n",
    "\n",
    "    #Same with pixels with min=255 (white pixels)\n",
    "    dropped_pixels_w = []\n",
    "    for col in changing_pixels_df:\n",
    "        if changing_pixels_df[col].min() == 255:\n",
    "            changing_pixels_df.drop(columns=[col], inplace=True)\n",
    "            dropped_pixel_w.append(col)\n",
    "    print(\"\\n Constantly white pixels that have been dropped: {}\".format(dropped_pixels_b))\n",
    "\n",
    "    print(changing_pixels_df.head())\n",
    "    print(\"Remaining pixels: {}\".format(len(changing_pixels_df.columns)))\n",
    "    print(\"Pixels removed: {}\".format(784-len(changing_pixels_df.columns)))\n",
    "    \n",
    "    return changing_pixels_df, dropped_pixels_b + dropped_pixels_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_const_train_8, dropped_pixels = remove_constant_pixels(mnist_8x8_train)\n",
    "rm_const_train_28, dropped_pixels = remove_constant_pixels(mnist_28x28_train)\n",
    "rm_const_test_8, dropped_pixels = remove_constant_pixels(mnist_8x8_test)\n",
    "rm_const_test_28, dropped_pixels = remove_constant_pixels(mnist_28x28_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale and convert to black and white\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "def rescale_decolourize(image):\n",
    "    #print(image)\n",
    "    pmin, pmax = image.min(), image.max()\n",
    "    rescaled_image = 255 * (image - pmin) / (pmax - pmin)\n",
    "    rescaled_pixels = rescaled_image\n",
    "    print(rescaled_pixels)\n",
    "\n",
    "    i = 0\n",
    "    for m in rescaled_pixels:\n",
    "        if i < 10:\n",
    "            plt.imshow(m)\n",
    "            plt.show()\n",
    "            i += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Only black or white pixels\n",
    "    for i in range(len(image[0])):\n",
    "        for j, x in enumerate(rescaled_pixels[i]):\n",
    "            image[i][j] = 0 if x < 128 else 255\n",
    "    return image\n",
    "    # return image.apply(lambda x: 0 if x<128 else 255)\n",
    "    # bw_image = image.values.reshape((8,8))\n",
    "    # return bw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_8_train = np.full_like(mnist_8x8_train, fill_value=0)\n",
    "for i, pic in enumerate(mnist_8x8_train):\n",
    "    print(mnist_8x8_train[0])\n",
    "    resize_8_train[i] = rescale_decolourize(pic)\n",
    "    \n",
    "resize_8_test = np.full_like(mnist_8x8_test, fill_value=0)\n",
    "for i, pic in enumerate(mnist_8x8_test):\n",
    "    resize_8_test[i] = rescale_decolourize(pic)  \n",
    "    \n",
    "# i = 0\n",
    "# for m in resize_8_train:\n",
    "#     if i < 10:\n",
    "#         plt.imshow(m)\n",
    "#         plt.show()\n",
    "#         i += 1\n",
    "#     else:\n",
    "#         pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
